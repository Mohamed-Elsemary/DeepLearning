{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMikiH51KRZh5pYMzWDpX3Q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "hCQ8_DzwyuJB"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "# handwritten digits from 0 to 9\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
        " # X_train -> we have 60,000 training images, each of size 28x28 pixels\n",
        " # y_train -> we have 60,000 trainig labels-- one for each image\n",
        " # X_test -> we have 10000 testing images, each of size 28x28 pixels\n",
        " # y_test -> we have 10000 test labels, one for each image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKPZa6Cq0Env",
        "outputId": "28108cc8-2889-427d-b3b8-c06f5b89c39d"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.min(), X_train.max(), X_test.min(), X_test.max()\n",
        "# min 0 , max 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aivhb-Fy7uia",
        "outputId": "d712b7b1-24cf-4a72-964a-da7e73d7a21c"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.uint8(0), np.uint8(255), np.uint8(0), np.uint8(255))"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X_train[12], cmap='gray')\n",
        "# use different values to get overview of the data\n",
        "# X_train[0]\n",
        "# X_train[10]\n",
        "# X_train[59999]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "GMGJmq5i8J31",
        "outputId": "c0dc868e-9545-449c-8ff0-d2cd99ba9659"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c3ebfce3b90>"
            ]
          },
          "metadata": {},
          "execution_count": 149
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# we need to change it from 2D to 1D as the inputs (x1,x2,..,xn-1,xn) are vectors \"1D\"**"
      ],
      "metadata": {
        "id": "Bmuip9O9A71o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before normalization:\")\n",
        "print(f\"X_train original: min={X_train.min()}, max={X_train.max()}\")\n",
        "print(f\"X_test original: min={X_test.min()}, max={X_test.max()}\")\n",
        "# Flattening the images\n",
        "X_train = X_train.reshape(-1, 28*28)/255\n",
        "X_test = X_test.reshape(-1, 28*28)/255\n",
        "# Normalizing the images (MinMax)\n",
        "# X_train = X_train\n",
        "# X_test = X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG72HstQ-wg1",
        "outputId": "d87c9be9-d636-4e97-f7e3-f9a4a030d180"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before normalization:\n",
            "X_train original: min=0, max=255\n",
            "X_test original: min=0, max=255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGWVP6mBATgu",
        "outputId": "c8ec44fc-3e7a-464a-85c2-5a09880bac74"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (60000,), (10000, 784), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.min(), X_train.max(),X_test.min(), X_test.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seXNKdIE-5DL",
        "outputId": "f71db74c-47b7-41b2-d6ec-3af32bf93d93"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(1.0))"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train[0] is one image image from 60,000 training images\n",
        "X_train[0] # 784 elements\n",
        "\n",
        "#That number, 784, is very typical for image data that’s been flattened from a 28 × 28 pixel grayscale image (28 × 28 = 784).\n",
        "#Each number is the normalized pixel intensity, usually between 0.0 and 1.0.\n",
        "# 0 is totally black # 1 is totally white"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz_NRgVcADM2",
        "outputId": "d3b70656-8e3c-4a6c-eaa8-e2dfb6d40379"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
              "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
              "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
              "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
              "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
              "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
              "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
              "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
              "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
              "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
              "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
              "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
              "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
              "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
              "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
              "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
              "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
              "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
              "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Keras Model***"
      ],
      "metadata": {
        "id": "jT207W9QEe18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "HXJVE0FfF2Sf"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to categorical one-hot encoding\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "1giR2OwIGcJa"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# before that it was number 5\n",
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLIyHCKoGpcg",
        "outputId": "e1aed4e8-f03a-4bbd-9116-f222f8c2707c"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# before that it was number 8\n",
        "y_train[59999]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHCC8D7lGq0A",
        "outputId": "5fe5392a-5263-46ce-fc13-81986ac656f3"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model.\n",
        "# Dense layer: each neuron takes input from all the previous neurons\n",
        "# and its output goes to the all neurons of the next layer.\n",
        "# in sequential, we define the form of each layer\n",
        "# We can skip the input layer and just add the number of inputs(features) in the first hidden layer\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(784,)), # first hidden layer\n",
        "    Dense(64, activation='relu'), # second hidden layer\n",
        "    Dense(10, activation='softmax') # third hidden layer\n",
        "    # 64 is the number of neurons\n",
        "    ])\n",
        "\n",
        "# Compile the model.\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model summary.\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ki9ZTZi5KQGw",
        "outputId": "5d21ea01-12c5-4589-8eb2-2ce36d544c5f"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,050\u001b[0m (215.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,050</span> (215.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,050\u001b[0m (215.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,050</span> (215.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> First Hidden Layer\n",
        "* No. of inputs:  784\n",
        "* No. of neurons in hidden layer 1:  64\n",
        "* Total No. of Parameters:  784*64 (Input-hidden1 weights) + 64 (hidden1 biases)= 50240\n",
        "\n",
        "> Second Hidden Layer\n",
        "* No. of inputs:  64\n",
        "* No. of neurons in hidden layer 2:  64\n",
        "* Total No. of Parameters:  64*64 (hidden1-hidden2 weights) + 64 (hidden2 biases)= 4160\n",
        "\n",
        "> Output Layer\n",
        "* No. of inputs:  64\n",
        "* No. of neurons in output layer:  10\n",
        "* Total No. of Parameters:  64*10 (hidden2-output weights) + 10 (output biases)= 650\n",
        "\n",
        "> Total No. of Parameters:  50240+4160+650= 55050"
      ],
      "metadata": {
        "id": "xv_U-NIkOKh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "print(\"Training Complete\")\n",
        "print(\"Evaluating Model on the test data..\")\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTuB0379PBZC",
        "outputId": "56ecade1-8384-469d-8bc2-7427fa4657e8"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8565 - loss: 0.4844\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9582 - loss: 0.1363\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9722 - loss: 0.0896\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9774 - loss: 0.0719\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.0553\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0444\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9870 - loss: 0.0400\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0346\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0285\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0256\n",
            "Training Complete\n",
            "Evaluating Model on the test data..\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 0.1343\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11814326047897339, 0.972000002861023]"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TlswzXoUQkwa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}